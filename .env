# .env (used automatically by dotenv)
# DMR configuration:
OPENAI_API_BASE=http://localhost:12434/engines/llama.cpp/v1
OPENAI_API_KEY=none
MODEL_ID=ai/gpt-oss:latest

# vLLM configuration (uncomment to use vLLM):
# OPENAI_API_BASE=http://localhost:8000/v1
# OPENAI_API_KEY=
# OPENAI_MODEL=llama2-7b-chat-hf